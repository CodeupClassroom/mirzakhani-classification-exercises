{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9163bb59",
   "metadata": {},
   "source": [
    "# KNN\n",
    "\n",
    "### What is KNN?\n",
    "\n",
    "- Supervised Algorithm\n",
    "- Makes predictions based on how close a new data point is to known data points.\n",
    "- Lazy\n",
    "- Sensitive to scaling\n",
    "\n",
    "Link: [KNN Diagram](https://cambridgecoding.files.wordpress.com/2016/01/knn2.jpg)\n",
    "\n",
    "#### Pros:\n",
    "1. Simple\n",
    "2. Robust to noise\n",
    "3. Effective with large datasets\n",
    "4. Performs calculations \"just in time\"\n",
    "5. Data is easy to keep up to date to keep predictions accurate\n",
    "\n",
    "#### Cons:\n",
    "1. Need to determine how many neighbors is optimal\n",
    "2. Computation cost is high (has to calculate every single distance to every feature)\n",
    "3. Euclidean volume increases exponentially as number of features increases (curse of dimensionality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e872ae33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Data handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Sklearn modules\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "\n",
    "# Data acquisition\n",
    "from pydataset import data\n",
    "\n",
    "# Data modeling\n",
    "from model import map_setosa_knn, train_validate_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0c04b9",
   "metadata": {},
   "source": [
    "## Acquire (Iris Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3a492b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read Iris data from pydatset\n",
    "df = data('iris')\n",
    "\n",
    "# convert column names to lowercase, replace '.' in column names with '_'\n",
    "df.columns = [col.lower().replace('.', '_') for col in df]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8af03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa795b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.species.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ceb089",
   "metadata": {},
   "source": [
    "## Prepare/Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33390c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, validate, test\n",
    "train, validate, test = train_validate_test_split(df, target='species', seed=123)\n",
    "\n",
    "# create X & y version of train/validate/test\n",
    "# where X contains the features we want to use and y is a series with just the target variable\n",
    "\n",
    "X_train = train.drop(columns=['species', 'petal_length', 'petal_width'])\n",
    "y_train = train.species\n",
    "\n",
    "X_validate = validate.drop(columns=['species', 'petal_length', 'petal_width'])\n",
    "y_validate = validate.species\n",
    "\n",
    "X_test = test.drop(columns=['species', 'petal_length', 'petal_width'])\n",
    "y_test = test.species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e80f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=X_train, x='sepal_length', y='sepal_width')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d165a2cb",
   "metadata": {},
   "source": [
    "## Train Model\n",
    "\n",
    "#### Create KNN Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf08ef82",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn1 = KNeighborsClassifier(n_neighbors=1, weights='uniform')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec61bcf1",
   "metadata": {},
   "source": [
    "#### Fit the Model to the Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5354fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8dfbcc8",
   "metadata": {},
   "source": [
    "#### Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76be200",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn1.predict(X_train)\n",
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fc4c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4c70e5",
   "metadata": {},
   "source": [
    "#### Estimate Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d1fee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = knn1.predict_proba(X_train)\n",
    "y_pred_proba[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913df819",
   "metadata": {},
   "source": [
    "## Evaluate Model\n",
    "\n",
    "**Note**: This next visualization is from a custom module (model.py). It has significant limitations and should not be used outside of this tutorial. Unfortunately, there is not an easy way to visualize KNN models. Many KNN models will be impossible to visually represent on a 2-D or 3-D plane anyways, due to the number of features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fab74b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "map_setosa_knn(X_train, y_train, knn1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e3bdf1",
   "metadata": {},
   "source": [
    "#### Compute the Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b7c632",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of KNN classifier on training set: {:.2f}'\n",
    "     .format(knn1.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567f288e",
   "metadata": {},
   "source": [
    "#### Create a Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10c79f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468d0bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efdc35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(knn1, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad07d2dc",
   "metadata": {},
   "source": [
    "#### Create a Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96e042e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TN, FP, FN, TP = confusion_matrix(y_train, y_pred).ravel() # Why is this line of code failing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78158d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06634c05",
   "metadata": {},
   "source": [
    "## Lets Do it Again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d35707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create KNN Object\n",
    "knn5 = KNeighborsClassifier(n_neighbors=5, weights='uniform')\n",
    "\n",
    "# Fit object to training data\n",
    "knn5.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on training data\n",
    "y_pred5 = knn5.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54930e4",
   "metadata": {},
   "source": [
    "How does the boundary map for **k = 5** compared to **k = 1**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4946bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_setosa_knn(X_train, y_train, knn5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160d4da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_setosa_knn(X_train, y_train, knn1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185184e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the new model\n",
    "\n",
    "print('Accuracy of KNN classifier on training set: {:.2f}'\n",
    "     .format(knn5.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c379a857",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(knn5, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577b1efe",
   "metadata": {},
   "source": [
    "It seems like our `knn1` model is better than our `knn5` model. But lets see how they perform on out-of-sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057e11d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Accuracy of KNN (k=1) classifier on validate set: {:.2f}'\n",
    "     .format(knn1.score(X_validate, y_validate)))\n",
    "\n",
    "print('Accuracy of KNN (k=5) classifier on validate set: {:.2f}'\n",
    "     .format(knn5.score(X_validate, y_validate)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7745b090",
   "metadata": {},
   "source": [
    "Our second model is more performant on out of sample data. Furthermore, it has less of a drop between train score and validate score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc403b0",
   "metadata": {},
   "source": [
    "## Finding the Best value for k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa0db40",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_range = range(1, 20)\n",
    "train_scores = []\n",
    "validate_scores = []\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors = k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    train_scores.append(knn.score(X_train, y_train))\n",
    "    validate_scores.append(knn.score(X_validate, y_validate))\n",
    "plt.figure()\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('accuracy')\n",
    "plt.plot(k_range, train_scores, label='Train')\n",
    "plt.plot(k_range, validate_scores, label='Validate')\n",
    "plt.legend()\n",
    "plt.xticks([0,5,10,15,20])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362c0ec7",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "- We only used sepal_length and sepal_width. We can try new models with different and/or additional features. \n",
    "\n",
    "\n",
    "- There are other hyperparameters we can tweak\n",
    "    - 'weights': Uniform is the default (all points are treated equally), but we can switch to a 'distance' approach where nearer neighbors are given more weight in the voting process\n",
    "    - 'algorithm': Large datasets use a sampling algorithm to save on computational cost. We can try different samplers. \n",
    "    - 'metric': There is more than one way to measure distance\n",
    "\n",
    "\n",
    "- There are very similar models that we can try (RadiusNeighborsClassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f167edee",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "Continue working in your `model.ipynb` file with the titanic dataset.\n",
    "\n",
    "1. Fit a K-Nearest Neighbors classifier to your training sample and transform (i.e. make predictions on the training sample)\n",
    "\n",
    "2. Evaluate your results using the model score, confusion matrix, and classification report.\n",
    "\n",
    "3. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support.\n",
    "\n",
    "4. Run through steps 2-4 setting k to 10\n",
    "\n",
    "5. Run through setps 2-4 setting k to 20\n",
    "\n",
    "6. What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?\n",
    "\n",
    "7. Which model performs best on our out-of-sample data from validate?\n",
    "\n",
    "-------\n",
    "\n",
    "Once you have completed work on the titanic dataset, try building some knn models with your telco data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114f218e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
